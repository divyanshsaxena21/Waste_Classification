{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyPjtagRfx/fl2zFkEvfCaz9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyanshsaxena21/Waste_Classification/blob/main/Waste.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umY3cOOI88pI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16353b0f-fbc8-4a0a-98b0-e923e8fcd751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/sumn2u/garbage-classification-v2\n",
            "License(s): MIT\n",
            "Downloading garbage-classification-v2.zip to /content\n",
            " 98% 729M/744M [00:04<00:00, 154MB/s]\n",
            "100% 744M/744M [00:04<00:00, 156MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download sumn2u/garbage-classification-v2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/garbage-classification-v2.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content')"
      ],
      "metadata": {
        "id": "X0LWEdBa936A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kiU58DIC970Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "cDclX3IO-Fvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q4px54VS-GUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "dataset_dir = '/content/garbage-dataset'  # Path to your dataset\n",
        "train_dir = '/content/train'  # Path for the training set\n",
        "test_dir = '/content/test'  # Path for the testing set\n",
        "test_size = 0.2  # Proportion of data for testing (e.g., 0.2 for 20%)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "FXshZJHZ-GsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "8PbvvaOV-ILR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "for class_name in os.listdir(dataset_dir):\n",
        "    class_dir = os.path.join(dataset_dir, class_name)\n",
        "    images = os.listdir(class_dir)\n",
        "    train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)  # Use random_state for reproducibility\n",
        "\n",
        "    # Move images to respective directories\n",
        "    for image in train_images:\n",
        "        src_path = os.path.join(class_dir, image)\n",
        "        dst_path = os.path.join(train_dir, class_name, image)\n",
        "        os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
        "        shutil.copy(src_path, dst_path)\n",
        "\n",
        "    for image in test_images:\n",
        "        src_path = os.path.join(class_dir, image)\n",
        "        dst_path = os.path.join(test_dir, class_name, image)\n",
        "        os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
        "        shutil.copy(src_path, dst_path)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "hqsgqzDy-I_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "nLnDNS-5-JLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Dense(10, activation='softmax')  # 10 categories\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ChKY04j-xYZ",
        "outputId": "5f4bc8fd-1d76-41b7-b63d-d0bc750e6401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image size\n",
        "img_size = (128, 128)\n",
        "\n",
        "# Prepare data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize images\n",
        "    rotation_range=20,  # Random rotation\n",
        "    width_shift_range=0.2,  # Horizontal shift\n",
        "    height_shift_range=0.2,  # Vertical shift\n",
        "    shear_range=0.2,  # Shearing\n",
        "    zoom_range=0.2,  # Zoom\n",
        "    horizontal_flip=True,  # Flip images randomly\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Normalize images\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/train',  # Correct path to train data\n",
        "    target_size=img_size,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    '/content/test',  # Correct path to test data\n",
        "    target_size=img_size,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9cfblkE-sFQ",
        "outputId": "4e402641-23ab-4189-d3c2-fb8d9af86d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15806 images belonging to 10 classes.\n",
            "Found 3956 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training class indices:\", train_generator.class_indices)\n",
        "print(\"Number of training samples:\", train_generator.samples)\n",
        "print(\"Number of test samples:\", validation_generator.samples)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqmTS1MXAE_b",
        "outputId": "7ae58479-49bb-4c84-e1e2-3083777647dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training class indices: {'battery': 0, 'biological': 1, 'cardboard': 2, 'clothes': 3, 'glass': 4, 'metal': 5, 'paper': 6, 'plastic': 7, 'shoes': 8, 'trash': 9}\n",
            "Number of training samples: 15806\n",
            "Number of test samples: 3956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(train_generator)\n",
        "print(x_batch.shape)  # Should print (batch_size, img_height, img_width, 3)\n",
        "print(y_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kevGIY4kAOrH",
        "outputId": "35ff5354-cde3-4b06-951f-f622b92f91d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 128, 128, 3)\n",
            "(32, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "Ss9C8htE-9Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAsJtRM4_BP6",
        "outputId": "47801452-29ef-4330-a868-da56da6625ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 935ms/step - accuracy: 0.3303 - loss: 1.9621 - val_accuracy: 0.4822 - val_loss: 1.5293\n",
            "Epoch 2/20\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275us/step - accuracy: 0.4688 - loss: 1.4565 - val_accuracy: 0.5500 - val_loss: 1.2711\n",
            "Epoch 3/20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.11/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 921ms/step - accuracy: 0.4445 - loss: 1.6285 - val_accuracy: 0.5396 - val_loss: 1.3151\n",
            "Epoch 4/20\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 245us/step - accuracy: 0.4375 - loss: 1.4384 - val_accuracy: 0.5500 - val_loss: 1.1811\n",
            "Epoch 5/20\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 920ms/step - accuracy: 0.4919 - loss: 1.4951 - val_accuracy: 0.5376 - val_loss: 1.3100\n",
            "Epoch 6/20\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224us/step - accuracy: 0.5938 - loss: 1.1744 - val_accuracy: 0.6000 - val_loss: 1.3025\n",
            "Epoch 7/20\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 918ms/step - accuracy: 0.5158 - loss: 1.4191 - val_accuracy: 0.5279 - val_loss: 1.3915\n",
            "Epoch 8/20\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383us/step - accuracy: 0.5938 - loss: 1.4530 - val_accuracy: 0.7000 - val_loss: 0.8091\n",
            "Epoch 9/20\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 918ms/step - accuracy: 0.5338 - loss: 1.3654 - val_accuracy: 0.6118 - val_loss: 1.1139\n",
            "Epoch 10/20\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 214us/step - accuracy: 0.4375 - loss: 1.7249 - val_accuracy: 0.7000 - val_loss: 0.8319\n",
            "Epoch 11/20\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 924ms/step - accuracy: 0.5500 - loss: 1.3013 - val_accuracy: 0.6369 - val_loss: 1.0976\n",
            "Epoch 12/20\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238us/step - accuracy: 0.7500 - loss: 0.8410 - val_accuracy: 0.6500 - val_loss: 1.0141\n",
            "Epoch 13/20\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 927ms/step - accuracy: 0.5784 - loss: 1.2527 - val_accuracy: 0.6146 - val_loss: 1.1433\n",
            "Epoch 14/20\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425us/step - accuracy: 0.5938 - loss: 1.3516 - val_accuracy: 0.7500 - val_loss: 0.5788\n",
            "Epoch 15/20\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 930ms/step - accuracy: 0.5857 - loss: 1.2323 - val_accuracy: 0.6448 - val_loss: 1.0799\n",
            "Epoch 16/20\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 248us/step - accuracy: 0.7812 - loss: 0.9311 - val_accuracy: 0.7000 - val_loss: 0.6440\n",
            "Epoch 17/20\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 931ms/step - accuracy: 0.5973 - loss: 1.1874 - val_accuracy: 0.6583 - val_loss: 1.0206\n",
            "Epoch 18/20\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236us/step - accuracy: 0.5625 - loss: 1.1967 - val_accuracy: 0.7000 - val_loss: 0.8967\n",
            "Epoch 19/20\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 925ms/step - accuracy: 0.6099 - loss: 1.1454 - val_accuracy: 0.6593 - val_loss: 1.0624\n",
            "Epoch 20/20\n",
            "\u001b[1m493/493\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239us/step - accuracy: 0.5938 - loss: 1.2049 - val_accuracy: 0.5500 - val_loss: 1.3773\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(validation_generator, steps=validation_generator.samples // validation_generator.batch_size)\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Test loss:', test_loss)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9pdIO8JSseY",
        "outputId": "d130ef82-a9d2-4d5d-9819-7f92130b5d60"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 225ms/step - accuracy: 0.6663 - loss: 1.0360\n",
            "Test accuracy: 0.658790647983551\n",
            "Test loss: 1.0662403106689453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eZaz4vsFAVqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess a new image\n",
        "img_path = input(\"Enter path: \\n\")  # Path to your new image\n",
        "img = image.load_img(img_path, target_size=(128, 128))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0  # Normalize\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model.predict(img_array)\n",
        "predicted_class_index = np.argmax(prediction)\n",
        "\n",
        "# Get the class labels\n",
        "class_labels = list(train_generator.class_indices.keys())  # Get class labels from the generator\n",
        "\n",
        "# Print the predicted class\n",
        "print(\"Predicted class:\", class_labels[predicted_class_index])"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juhPW-T5S2W9",
        "outputId": "4b8f3153-0c2e-44e7-c445-18f402a8fb20"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter path: \n",
            "/content/test/battery/battery_122.jpg\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Predicted class: battery\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Image\n",
        "\n",
        "# Load and preprocess a new image\n",
        "img_path = input(\"Enter image path: \\n\")  # Path to your new image\n",
        "img = image.load_img(img_path, target_size=(128, 128))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0  # Normalize\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model.predict(img_array)\n",
        "predicted_class_index = np.argmax(prediction)\n",
        "\n",
        "# Get the class labels\n",
        "class_labels = list(train_generator.class_indices.keys())  # Get class labels from the generator\n",
        "\n",
        "# Print the predicted class\n",
        "print(\"Predicted class:\", class_labels[predicted_class_index])\n",
        "\n",
        "# Display the image using IPython.display.Image\n",
        "display(Image(filename=img_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "EhploJJBS4qR",
        "outputId": "b1fb9a97-93c3-4a9b-8a31-81911fd2b7f6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter image path: \n",
            "/content/test/plastic/plastic_101.jpg\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Predicted class: plastic\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEAAkGBxISEhUSEhIVFRUVFxgWFxYWFRUVFhUVFRUWFhUZFRYYHSggGRolHRUXIjEiJSkrLi4uGB8zODMtNygtLisBCgoKDg0OGxAQGi0lHyItKy0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLf/AABEIALkBEQMBIgACEQEDEQH/xAAbAAACAwEBAQAAAAAAAAAAAAADBAECBQAGB//EAEQQAAEDAwIDBQQIAwYFBQEAAAEAAhEDEiEEMQVBURMiYXGBBjKRoRQjQlKxwdHwcpLhU2KCorLSJDODk/FDRKPC0xX/xAAZAQEBAQEBAQAAAAAAAAAAAAAAAQIDBQT/xAAjEQEBAQEBAQEAAgEFAQAAAAAAARECITESA0EyQlFhcYEi/9oADAMBAAIRAxEAPwDxNqsGolqkNXqviDtVgEQNUhqYBhqtaiWq1quAIarAIoYrBiYA2qbUaxTYrgBapDEcMUhiYbQLFNqPYpsTDS9i6xMWKbEw0tYusTNi6xMNL2KC1MWKLEw0vYusTFi6xMNL2LrEcsU2JhpexdYmLF1iYaBYutR7F1iYbQbFFiYtUWJhoFi7s0xauLVU9L9mu7NMWrrUPS/ZrkxauQ9J2qwaihqsGqKEGqwYiBiuGKgIarhiKGKwYgCGqQ1GsVhTRAbVIYjWK9iAAYpsRwxSGIAWKQxHFNT2aAAYpsR7F1iBcsUWJns13ZoFrFxYmezXdmgVsXWJns1xpoaUsXWpksUWIF7V0JgsVSxAGFyLaqlqCkLoVrVWEHKFxaohBK6QqwoIQXkLlS1cpo4NVgxFDFYNVUOxWDEYMVg1ECDFnP4lDiLNiRN0TBja3C2GsWKeH1C58U3kSSCKZIMnlv1+RWuPz/qY/kvWeGtBre0cW2xAnecSB0HVaAYs/hGlc2o65rmm0DvMLZk8p/h+a1wxO83xedz15Xi3G6tOq+m0Mhsbgk5aCc3ePRNez3FX1nuY8Nwy4Wgg4c0Hcn7yU4zo7673DvAxtAAIbESZnb4pr2a03Z1HXd25oDZjvZnBxnAxz9Fcn5T9e43bFYU0exSGLDQIYpFNGsVg1AFrMrxVXX6ovc26oCHEWtERk4gBe1114pvNP3wxxbse8Gm3fG/VeFbQ1AMupPJO5fRunn9tpyt8ZvrPV8E+masCbqo82mPmFtcJ4pNImoS57SZAaJtgQXbNAknJIlYFTtIgUs+FBo6bGwQtr2Y0j6l7a7HWNtLGvvtkzPdPdJwOWFvrMTktW1eo1LnNpS1oMd0wI/vVPy8ditzhXD+xphhMmZccxJiYnlj8TzWoykAAAAANgAAB5AbKbFyvWzGpCti6xMliixRS3ZpQ6kXFoB7uJxE84WnYsUva2pUuB94nHjnkDO+3itcSVju9SeG7sxH4R+KmoAASTAAkk4AA3mdkKjWa6qGtnAJz4QJnmO8OXqr8ZpzQq/wO/Db129VLPV/jvVn/ANFzraP9qz+YIrCHC5pBB5gyOi8ZTbg7bfmP1XrOAM+oZ5u/1H9V07/jnM3Tju9XBy1RamC1QWLk2Wc1VtTJaq2qaAWqtqYsUWqaAQuRrVyCzWq4aiNarhiuqEGq4aiBiFxB5ZTc4bgY8CSGg+kz6JEP6Tg9Sq2Q5rB1dMmN4xtynzTtPggAh72ugQIDupMnIkmenzknM4dxasQ1gDnNAAm2cDxhaoqm2XvzJgCJtBgFwjc7/Pms39RnJayddwh7HXMe3ckAz/VLvvfTPZNucHBpAIxvdufCMdfBaeoqtjJMRJM7ZjMbLyXCdYaeqfypudacyTJMOJOSdt+sLUt/ssyeN9ujHLRvb4HUsAGOjvwQdVwx7tm02eDqj3f6RCcqcQZyuPn/AEStXifQALUtc8F0FU+48y9vgRcPvCd+k+E8wnLF5qhUdW1lPPuCcdJk/IEeq9ZYs10gNis2mTgCT0RrFrcJ0oHeO/IdAVm3IpR/AnlrYLZmXAmPIDrz+SLS4GftujwYW/Mn8gtSoUIkrn++mcn0q/guDa5wP95zXD8ZSjuBuFSSRbzM7gxOOuFqglTKTqz+0vM3Xna2nLTB/wDKpYtvV0JHlkLKtXSXWgLFFiYsUFqapWp3RP7J5D4pjhvssHtLy4hzySTk7mQd+kY5Kumo9pVt+yw58XEbeQXr9M5Tvu8zz6kmvIcT9mfo8ajtC6DDgRydkkmeoB8wsnVvc66nSaXECHkC62RsAMl0H08V9I11AVabmH7Qj15LxWgaKJcw4hx5cyc+eZT+Pu2e/YWWV5kcDcAR2L8iD9XVncHp4J3RU30mtY+m9rNmudTewSSTaS4ZO8Fex0+sBOCevoNz8l3Fava0nUxY4uBHfc5oE85DSZGD6Ld/kt8xmTHmS1VLEdlJwAD4LgAHEbF0ZI891BYpXQuWqpamCxVLFAvautR7FW1FCtXItq5AQMV2tRAxXDEAw1C1lB7mEMEuwY5EAgun/Dcq8S4i2hbc1zi6YDY5RuSfFKDj9E92pTq2nDrS26Orc7rU56zZGLZ8aWlN0NaGjnhxpt8cXBo9Alalfwz5un5H9ymtJpBaCXhkMBu7QwSSYL+zfknE5kSPIr1aZb3QxrhOTLnic5O7vUBNick69Z0E4EAkm1rtvEg5Jx5kLG4O94r3kd5tQPAI+6WkS3z5wvTabTRTq2kNLaZJDQ4zthhcwOv8+U5CxOB0Wxhrs94Ofh0S6RAJGSQeotSZTq+NXi8Oqve0QHm+Jm0uy4T0BJWZWatvWi510NGAIaIGABMeMT5kpKpQ/f6ytz4xAPZCjdVq1Puw0ecD8pXrbVmeymnaKTnNcHXPcSQ2wTOwHQTjZbdi5dXK3zdgVMC5oPM/1W0HNMbHosPUuDSwmIk4PlHxyiU9QJlotwQQCTdIgkg45zHgs2b6WtN5HU/FyA+uASJcY6H80nWqTugGOvzScmtEapvMuHiYTRb1uEic4xyOeSw4HU/FGo1LRg4UvJrQqgefmZ+UrOquF8deXQgf0Q9VVODcY5gED4FZ3btFVpLi1u0ve2Z38QNlvnmpuTWrYqVTa0uPIE/ASqaTXNqValNjmuDA04IJlxdMRywPircZaewqRuRA8y4BP7WXZpTgWqlod97PxK3aepIjO4ncH9leW0ek7BtKn2jXGxhFp3luMeWfIhblDSPI5fvyWbN+ttd2sGIJ2Ez15+i81x8zXwWtL2lwJMTa3IHibfiVqO0NUMLum458tuvosjX6G+rRe90S60C0uwRF3dIJyWiBnc8suZIxdrL/AP6Tgd5VzxVx3O/X1S+ooAPIaSROCRBInBIGyDX05IjP5LtMrNPcHc55qvdPvBgHi2S75uj0WgWLuG6PsqTGGJAkxBy4l24wYmPRBr8SpNcWG4lpgw3ms/b43+pJ6IWKlqijrqb3WgmehB5b52TLmrNmNSy/C1iqWpktVLUUKxcj2rlAQNVg1FDVNqDA9o9G55ploncbgbwRHwOVh6zRlhAdguMATMn0GF7Rjb6rQMgEA9MEOf8AJoHmmOLUrpwus/lvMkc/zOrrP4VQa2mHgCRgOc5wZloJbG0yehOdhhVqaQTc8NBMEYD2HYgiW2nH3SFr8LJdRI7pIPuEYECLh8j6nrklTGLi2Rs4Eg+Ticz4lxXK9bV5jArtux2hdJAlog7mRgmPOVX2d0JcS26bQLie/BlwAIaAZ8ztG2y0ddQdmA3O9oIn4Obn1CR9jWtpV6rGscwPbIkyHFpnHjl3XzWt88TqN2vohyDI8W1R+aSq6EdGegqE/NbdWrj9/volqlQY+c7TJ29IWJaYR4NP1jTMh0ifukQIECB3Vl+2uur0TRFBxbffNoaSSLLRkE8zstSjWArsH35b/lLh/pS/tNwsapzGWmWE94Z94e4GXCeRJ8I6rpzZ+9rNmc5HjX8S1xIufU3xeGgScDLhaPVfQBQj/wBs+eZtDvgWwvPV/Y8U+85ri0EEi2yRIkOJdIxIkL1+l1r3gHsnAHmWE7YMluZ81f5e5csZ5ln0rqawgX0yeeWVCR6wlzq6X3G/yv8A0WxX1lVo2eW9RTqED1iR8kq7iZ5l/qKy5SunhA6uj91v+b9FZtWidg7rgvx5EDHom28V/vH/AOVM0eJuIdBdEZ7r/wASJ+CWp4xHtoOJ7tUnw7Vx+ZH4ry3tA22sG2uADAYfMyS7IkneBz5L3zuIzs17v8NQ/jheR4sxmqrBwsYAIJLWm6DJzPoP6rr/ABdZfWeuf1Mjzvs5XcNbRLSRdUawxza5wBB8F7n2zqPZpxYJmo0HAOBLvxaFj6LhbKFWlXmm5rHTFrW3Atc0QSdxMjxaNt1u+2FVx0zKlLvNvY4luQWzM+I3+Xgn8nU67ljXPP5mAcP1rXMIw4kzIiW5l0REGJHktClq2iYA5898EBZ2l1LSBe1jgebmj5O3HoU3Q0+nku7Onnke+2eR70n5rm1hgcQO1zTHljr+/BZvtBxP3Q33w8WEOy0tcC0wMEyAM9Vog0WAubTphxdMw2AdjbPuzjAgfErJ1tGia1J7adMPvbOA1zpIxaN/MCQrzJvxmqU9C6dvwVeIaZzWkkEYxg7+i9Vp9EAftjfavV6Hmu4jwm9h3GN+1e75HCk/k9S8smjT7jRytb8LRC89qdCe1qG05dOHs5jplek0himLt2i138TMH4kSPNG4Zp57xElx8/H5YCs6/Otd8TuY8toNKRXb3TFrpMgjaNxHUYW4WLa47TimHge46TA5HDvxn0WXYpe/16vHM5mQsWKlqaLVQtTWwLFyPauU0Fa1dUMNLugJ+AV4SnGHltFxHIs9R2jZCS6GPZ+o11M1hs7utMES0bmDnLpzztVta4Zz5eP6Yz6IPAawbp2BxuFrxB5lznSfITA8vIquuc3LsTBEkgQMH8ucx8Uv+Sc/GT7M8ZD9S+jBtg55Xs6c5i5b9Sl3pa53kXu6ZGDETyheI0lMU9W0MYKZlpJJcA4ui7JLoG4O8ZC9eajzs6l/hvf8gArfEn12qaCILQJ6bHkcg/ivM8DqNZrezYXCC4EENgy08wAZB6/Erb1grkG1wH/RP/3qD8Fi+z2jcNW1xkmSXF1kmGnk0kegVn/adfHsa7kqXFO12oFizMGPWcfpWnG2Xu9Q0AD/ADL0nCmAtL3HY93wjmPH+q8xxRhNWnG4D4/lBj5LVo13taPq6zh0DR4nqPPfmtdTYzb69CNVPP0Jj4fH8UmwxUhrcPEmJi4QJgdRv/CFlVdY4x/w9ceg/wB6c4e57qzTa6G03DvNOLnU9gd4tPXksfnF1pVKr2g4P+Fjz8wEqeIOH9p/JV/RP1nVAJAJHMNYSfgNkq3VPBMh8cvq6n9ViEBPEj95/wDLV/RHoaxxBMk4zLXjHhK468/3/wCSp+iIzXOzhxH8D/zCprqFTtJnYdQc4nZ3LI/collOpP1YMHMtb1+eyx9bWLnkS5uW4IcNhImDt8E/ReWiZwB/eP5pY1Ba3DmFs9m0EQ6Ghon7wn1PrHRef9pHOZReymCLrTbJBxmACecbeHmt0V7xJGxcNzOCRMCOmy8v7WVXNdSh2xbvJA7/ADbOefPyW+Jdys9C8F7OMscARMFrzMeADvki0amlcYsI/wC60+Gf6Iml4iWt/wDTHQkOB6YITjeKNLbbqcdS0bDbBwEu6sKanS0T/wAp1Rpye8S8QBsQQPHmk+FsY2vgyQznIAyB3A4T4wNhzytZ2oo5l9GPGmBB55BAjdY2rcw16LmVA7NvdaQBh2B3jAMla598Z6er0upAIOMcjsmu2wsOkTKbaXQuN5a1h8d1QZVFOP8AnEO8yxpLp+DE9wxjHA25+8Adz+E488rE4+1prMFRpILTlshwjOHD3Z2nO61uHUhSDS2bOVo70cpHjv8AuF0s8Xmt5tKm7u97YCZc1/iLgZjfnyCy9RQDXFrdgYHgIED5olfVtcILnU/GXMg+ZA6DCS0VS51SHucO4ZdBNxbDhIwR3fkVjmKuWqhamC1UtVUCxSi2rldHNCDxAfVPkkANJMRloEuGQRkAjbmjtKW4s4ihVIAJtIgwRBwd8bEpi2sjgNR7GWto0yJMkCHxvBAFvwJ8t5NxB4aDayD0F9M/IfkgcLqsLbnteCDM3dBvBMYITmsLQwkGoAeTTTaZJ3kkD4ldL9Y5ed4W2q+tTe65uW5kMgD3oc4AZzG3ReuqUCRntD/1P/ykrzXC9UDWpll83gEvqMe4AmDAZImCczK9ZUg/ae7zDx+gU7vxIzdXoQGkw538RquPpe9qQ9n6QGoYAYAuhoAABtPK49Fr6im0tPcHnFOR8LjKU4NTcNS2YAh2OZ7u2GhWXxnp6KrTS72rQe1LVmrjK2weIth7XGYbJkXSO7uLc48E86qHtB7Z48A0Hmc94T8VSv74ONueRyG2Z3WpS1dGwSGOic2ADc7SBhbt+M56xi1sj6+pvuWUxHjgJ/g9Udr3X3xTInuANBc2fdEEmG/Ao9TVaeQYp4OcMPI9Cj6SvNX6prSOzk2lrY7+JA55Px8Vnq+Lnp3tXx7r/IAE/AFUGpP3an/bcfwCONQR9h3xb/uVfpI+4/8AlB/Arl/4oR1nhU/7VT/apGp/uv8A5HfmifSm/cf/ACFd9J6Mf/KB+JV3/gYuoh1V19EHLYLqJcQA0c7TBnyT1UdwwOn4hKV2vdUcWY7ww45DrWgCA1wt2O4K0a47p5/+Qt2/CFaTABUuAi8nwgtaT+a877R0y6rTbRY0Ox3OygO72e6RnAEY6r1FGR2nPvYG32G4/fVef9oq7m6ik5zGkAbENqCc5IePHzxhb4t/VZ68hzU6d7W9ylTqNPKCDIGDDHEz4kfor6ejOXado8GurEgeIAwmadC7TvcA1ocGzDQTAOLRT28dyk6OkLptq1DncNrzv5LE+EEq04IDaGJEkurG0czECf6rHqCoNRTljabZIwXy7Bx3hzg+sLZqacUiHufVdEGT9KMxsDJt5AbctkLidUvq0XkUyKhkWthzYBIJJJPMz81rjr1OjNNqcDMINJuU2G4WK08d7TUXGtSLTEAybajgJt37M3AY8uqY0urZBDqlIOG0vqD+a588+SNxItdXDHmAGiDdBuJgEDnz54kYKZo6g27vgYGaRx1APVdd8kOQDxDBDa1CcQG1qx88MN3wReFNMPJES4fembRPvkugkyJM55Imo4hgj67PTs2n4tMqvAx3HiCGh5i73sgEyefWTnPhKz/S/wBmXNQ4TDwguCw3IGuVoXKtF2OS/FWzRqYJ7p2wfMb7b+iIwoXFI7Gpv7pW59YIcGJDAO0JGcObtkjBg4wmq4dkiPA4+QsSnCH9zL2OzMOaAQT1AAym62xkNI8Yj5lb6+sc/GRQDu2pguc49q2GwQ05GThuJ8OQz09VUkbvYP4QAfmXLy7IFRokAdq0EMFOc5mA2Yx47RzC9Ha3k6ofIAfkFO/6XlWqCWnLj6PPLwhKcEZ/xLSWkYdl1x+ydi4nPkU3ETgkQRD3EjPhGCkOF6ZrK7SGNBN2Wkkkkc5AUjPT1b27xCVrDdD1WsbSYXvcAAJ6T5JXhmv7Zt0RMkDw/WFiS5oHXBuxvByDBGRscpttUWCaEbibp8RkMAGCD6pGrqxcS0g24jPNwH5LRZqnBo7074c3bqAaeOatT+y97bmxSMztPvT4AZWho6hFTDA0We7IjLmycDy38doEqP1+W3Mh04AySfMgQnNLUiqZ3LDtgABzZ33JkZ8BhZ63FPjUn7p9C38yFU6oc2uHqz/cpvEyfmfylT2g8fQLln/Dag1Tfuu/y/7lI1HRjviz/cr3jofgqPI8f35p4MfXNDnuLiW7YgOHujvd1riDGJwtKu/un99Fm8QIvJsDjAgxHdxi60jecYTtY90+n4jmunnhE0cmpBHvYxsbG7/j6rz3tKx4rU4fJtgAgbTkbR+eVvaV4PaycBxBMxENAOeSwePtb21OAYjLhjngZEGIJjfJ6Bb4/wAmO/jVoAdjDKfe+19oEeAbH4+iGym4bNYP+jW/Kpv4pqpTBotBaHYwS28jzJPh4qtHuD3CPEsx8JkLJyGxji/vMbAj7FXHxf67eiQ1jD9IpEgAZgwQSbTjy38Fp19QHGCW4jNsePM4GOcD4hZlZ7TXpQZgHpEEOMyDvkeG61zrPX2NpgTDThJB5RRUwudjbC4s8duyHGQJiTBB2DgDB689kwxpLQRnqIjkM5YSZSfEmRWBncGQQTs4HENMbgZ+KegEDuiI5W4wNpXW/E5+qV2mNy3xj8Pq2/iicE915lxl8y479xm3QDbc7HyVK7RHIHrDT+EruDu7rsk985Iie63Ych4eBUv+Lc+n3lBcrOchysOkVlSouUoM5rkLiLvqnxM28t/kqB6vUNzSOoIXVih8JaOya4wC7pAmDA+XTHRMVekn0nz3WdwzXClTIqFrLC4Wvlh6y12bgZ2tnxPINL2ko1IkOaD4g89sZCv5ttxmWSHRSF7dveaQ4kzIOLcE+EGN1tuXjeHuq1alwYWMa64XXkm0yA5xMkGMgePVa9c6pwkVWB14cIZDQ0CAIN2Zzz5bJYNioBad5/fhK8zqOJ1GPL6VPtOzy7DiDMiBb5n5J3VMr1GQ6pTaTiWsJEYzaeZyIlMcG0bKDbWEmYJJ+UdBv8VJ4fQdHXr6oOdUZ2dNzYAMyBa6S0RLjJByAO7zXl+CarUPrBlMOLmBwwLQGxmb4iYG8ZDV74Vcq30k9VZ/JnmJeZWPo+Hvo9pVcH/ZAcJDi5xZJDWmQGwRPQ4XoalGsGCbh0+tv+TgSEB1Uua5uMjE7SMifDC7iftPUFPsxo3vcD3XNtDD490Yb0HlJ5rnb11ZkTyD6Wm5xlzpiIFu/UwB8sJfiFOHkW3vsJYJDTAcwQ204PenM7CeUJ6D2grNf9Zo6sYhzRPnIyNvH05B6q413Go9pp7NaGloJAJdc4ZAJuiOjfFLLL6ffhGvqaY7rq1QEiZo6h7xt0c0uGCD0MjJWDxPjDGwKWp1jjnPatt8pLCcdIC39V7O0Khm0sI5sO89QcJB/sXSkEVqoIn+znO4kNGF0l4/tMuMjhXGw4xW1WsbPMPplo8+5I+a9Lw7V0X91mq1DzGA+r2ZceQb7pc4x158sLOZ7DUv7er8GcvMJ+h7L0G7guPUm31hpGU6vFXKJo3mrc5t4EwW1D2jmkEzMkx1+Sbqtq2xcYnPd3iDg4I5K+h0tPTg2g28wXFxOwwXSYG8ecbpHiHtXRphwDKrnDAHZVGtJmJ7Qti3xz4ArH25I1z89MntnYL3DBn6toknqYzj8klxA1G1KboJba7EQZkcmjHmengu4X7b0ahd2tN9Mg4sZUqtdv7payR5EDdMcXfTqPpv79rabhJuYLy5jojBGBUwfBJbOvYnXzw7p6xc0TDWkbEuyTvg7/FFdTpDnHl+kLtPRbAc0t64O0dYRGUBMh3zWbYRWwbgOAMxm2PMbj0Kyq9MiowueJu90Nke6ftkz+/Feg0mnLnWktPy+c/kvO+0Dm06wqvdZTpENnkHVA8iSPANO3inHXuM959OGsAYyjtcVkajjLe0a9svoNlrqjQS3douBjYT8iqn2moh1tImo7q0GwDmS4jIHgDyC1Ob/savqHsfWLYDnNwcSWnBA8Cmw9ojceRI/FedfoajXdvTpm1xALS3vOls9oQTMyT4nJ8VoarX0qbW/VPJiSC1zAN/tW+HPr0lbvP+xPPrTqvZzcfV7YHxco0rm9604u6yJtak+GcUo1RNlRh+7Dx4btEJpjtyBbJmJmOQk+nzWLM8rpL6MShuchud4oZcpjWi3rkG5cmQ1ktqKxqpFtRWNRdcQ3TqkjmrCsUmyoQrXq1MMtrmd/mj9qkAVe9SwOOq48VXTVspW9c16GNLtVXtUn2qjtFEO06+U016xw/KY7bCYNDtVelWysztlZtZTEbA1Cg6hZn0hU+kJ+Va4rqRXWP9JVvpKflGnW1E4UfSPFZRrKO3T8jW7YHc/ND1NNj22umI6/AjxSDdQrHUJidNvgjiymbnF7Z2wJzicmPgsXWv1ReXMrBsEgd1uGzMQWmcgb9OSkVoCr2yfn3Uktami4lVa2HkFxmXAQOWLY2kdUlV01N0l4D7jPezDswQCIH6GEHtUJ9dJM+Fhm4e7gDaIAAHTyQ2UmU5sa1s72tDZ84S/bKX6hVfTI1BOJRDWWUKsFE+kK4rQNVVFVI/SVX6Qpiw8aqoayS7dUNdMaP9quWf2y5MCjQpCkKwWxwVlCs1TRwCmFIVggqAphSpCghcpXJpjgplQVYKDgVMrguKGRYOUKApQyIK4FSVyCpKi5WK4IZEtKuHoZVmoliznoJcrvQ0JE3qpcuUORVblBcuKqUJI6V0qCuKutfmILlWVZyqomIuVblYqg3RrFpXKVyGP//Z\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fv5oWT_ZUqoV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}